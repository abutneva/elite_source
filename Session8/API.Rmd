---
title: "Accessing the Web"
author: "Marius Saeltzer"
date: "24 Februar 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(openxlsx)){install.packages("openxlsx")}
if(!require(readstata13)){install.packages("readstata13")}
if(!require(knitr)){install.packages("knitr")}
if(!require(jsonlite)){install.packages("jsonlite")}
if(!require(xml2)){install.packages("xml2")}
if(!require(foreign)){install.packages("foreign")}
if(!require(rvest)){install.packages("rvest")}
if(!require(httr)){install.packages("httr")}

```

# Web Sources for Data

One major objective of this course is to find data on the internet. As all of you know, we can download particular data sets from homepages, as you would do with the CSES or other surveys. Beyond this, we can access information from the internet directly. Last week we learned to download data from a so called API using a pre-programmed R package. Today, we will enter a world when R does not provide us with ready-made tools, but requires us to program our own access. This process is called webscraping, as it allows us to directly ask a server to provide us with particular information. 

Information can be stored in two particular ways: directly reading information from web pages or downloading information the webpage provider wants us to collect. The latter way is of course the easier way and is accessible through so caled Application Programming Interfaces. Today we will focus on the latter, while next week, we will focus on scraping homepages directly.

## Application Programming Interfaces

API's are information interfaces for programmers. They are amazing tools, as they allow us to retrieve customized information chunks. In so called REST API's, we send a web based request in form of a customized URL to a server and retrieve an answer. REST API's are basically servers, meaning computer programs offering services to clients. In this regard, we are the client and ask a web server for information. To do so, we send a REQUEST or QUERY to a server. 

Let's head back for a moment. Sending requests to a server is the most natural thing for our generation. Any time you open a random web page, we send a request to a server. To do so, we enter the server's URL in a browser, which is basically a web client. 

Like in a regular browser request, we need to formulate an URL. A URL is something you all typically work with, but most of you will only use the main URL and then click on links from there. However, most homepage subpages can be accessed by adding a / and the location of the subsite. In some other applications, this is even more flexible. You can "read" the automatically generated URL, for example by a wikipedia search for the term "API"

https://de.wikipedia.org/wiki/API

Now if you change the end into https://de.wikipedia.org/wiki/Hamster

and enter, you will go to a much cuter page. 

This means that you can manipulate the URL for your own advantage.

R can do the same thing: it can pass a request to a server, just like a web browser. The problem is just whether the server understands what we want from it 

## OPEN FEC

The example we will be working with today is the FEC OPEN DATA API. It contains all kind of campaign finance data. Of course, the FEC also provides data as downloadable csv or data bases, but in case of the latter, the data is often too large to be read in a regular working directory. Instead, we can access an API and tell the server very specifically what kind of information we want. 

In Twitter, we used the rweet package with ready made functions. These packages are called "wrappers" as they wrap the API requests in another programming language such as Python or R. In other words, it translates the internet language http, which is used to utter GET requests to a server, in a form that is more intuitive to users of the language. 

In terms of the FEC, there is a package by Robin Pollack. However it is not an official CRAN package, is difficult to install and in some cases contains errors. So let's build on his code and build our own API wrapper. 

First, we import the data set we know describes all active candidates:

```{r}

main<-read.csv("candidate_summary_2020.csv",stringsAsFactors = F)

```

## Authentification

As with the Twitter API, it is necessary to authenficate yourself to a web server. In some cases, data access is restricted, while in other cases the server wants to limit the number of accesses for technical reasons. 

You can easily gain access by registering your account on https://api.open.fec.gov/developers/

Now let's start with the FEC. Reading the documentation, we know that we can send requests to the API page: 

https://api.open.fec.gov/v1/


By adding the category, the search terms and the API key like this:

https://api.open.fec.gov/v1/candidate/S0SC00255/?api_key=n2u69fqFv4pcf0skAgak18rr6CtI19AIC5kmmMps

When we enter this into our browser, we will access a JSON table that contains all the information about the first candidate. 

So let's build a simple R wrapper for this, using the paste0 function and the httr package. 



```{r}

api_key="n2u69fqFv4pcf0skAgak18rr6CtI19AIC5kmmMps"

cand<-main$Cand_Id[245]

url<-paste0("https://api.open.fec.gov/v1/candidate/",cand,"?api_key=",api_key)

```


Now we just need to send this request to the server using the httr package. These requests are called GET request

```{r}

resp<-GET(url)



```
Which returns a list we can now read in as a JSON file.


```{r}

parsed <- jsonlite::fromJSON(content(c1, "text", encoding="UTF-8"), simplifyVector = FALSE)


parsed$results[[1]]

```

In other words, we could write a nice function: a wrapper to get any candidate by ID from the FEC database.

```{r}

get_candidate<-function(cand,api_key){
g1<-GET(paste0("https://api.open.fec.gov/v1/candidate/",cand,"?api_key=",api_key))
return(jsonlite::fromJSON(content(g1, "text", encoding="UTF-8"), simplifyVector = FALSE))
}



## Example:

#candlist<-list()
#for(i in 1:nrow(main)){
#  candlist[[i]]<-get_candidate(main$Cand_Id[i],api_key)
#}

```


# Problem Set  


Task 1 --Reading Code -- 

There is already the stump of a nice wrapper on Git. 

The following functions are extracted from the existing API by Robin Pollock on https://github.com/robinspollak/R.openFEC. 


It creates a list of all filings for a candidate,meaning all his donations. 

It contains a tiny flaw that stops it from working. Comment the code, explain what each step does and find the error. 

```{r}

get_candidate_committees_history(main$Cand_Id[1],api_key)


candidate_id<-main$Cand_Id[1]


get_candidate_committees_history <- function(candidate_id, api_key, query_params = list()){
  fec_api(path = paste("candidate/", candidate_id, "/committees/history/", sep = ""), api_key = api_key, query_params = query_params)
}

fec_api <- function(path, api_key, query_params = list()){
  url <- modify_url("https://api.open.fec.gov", path = paste("/v1", path, sep="/"), query = c(list(api_key=api_key), query_params))
  url
  resp <- GET(url)

# What do you think this chunk does?  
  
  if (status_code(resp) != 200) {
    stop(
      sprintf(
        "Open FEC API request failed [%s]\n%s\n<%s>",
        status_code(resp),
        resp$response
      ),
      call. = FALSE
    )
  }

# What do you think this does?
  if (http_type(resp) != "application/json"){
    stop("API did not return json", call. = FALSE)
  }

  parsed <- jsonlite::fromJSON(content(resp, "text", encoding="UTF-8"), simplifyVector = FALSE)

  structure(
    list(
      content = parsed,
      path = path,
      response = resp
    ),
    class = "fec_api"
  )
}

```

Try your code on the candidate Frederica Wilson

```{r}


```

Task 2 -- Writing Code -- 

The data we get here on Wilson is a little unstructured, we want it as a nice data.frame for our database. 

a) Find a way to press this file in a data frame as we did with the Abeordnetenwatch Data.


```{r}

```


b) Define it as a function


```{r}

```

c) Write a loop of some sort to create a dataset for all candidates of a given candidate. 


```{r}

```


 
### Follow the money API

```{r}
key<-"2862552ef44a7c15c5fd8a8d19c42d24"
request<-"dt=2&is-s=LA&is-y=2016&"
paste0('https://api.followthemoney.org/?',
request,
'APIKey=',key,',&mode=json')

```
 
## state and year

is: independent spending 

is-s=
  
is-y=
  
## individual information  
gro
  is-d-id #donor
  is-s-id #spender
  is-t-id #target 

lby: lobbying 